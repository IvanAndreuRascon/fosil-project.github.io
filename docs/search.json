[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of this site is to help foster open science in linguistics (FOSIL). The early 2010’s saw the reproducibility crisis take hold of the psychological sciences. As a consequence, there’s been a push for increased transparency and reproducible methodology to help mitigate the effects of questionable research practices. The resulting methodological framework and associated techniques, now referred to as open science, have reshaped research methods in psychology and have slowly but surely made their way into adjacent fields, such as linguistics. Important considerations often overlooked in the wake of the open science movement deal with (1) how linguists actually learn open science practices and (2) how senior researchers can train the next generation of linguists. Few, if any, researchers have had explicit instruction on the practices of open science as part of their professional training. Nonetheless, today’s speech researcher is expected to be up to date on the current protocols of open science in order incorporate the methodological practices aimed at improving reproducibility/replicability. The FOSIL project aims to make open science practices clear and accessible to people conducting research in the field of linguistics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fostering Open Science in Linguistics",
    "section": "",
    "text": "reproduciblecode/projects\n\n\n\n\npositionalitystatements\n\n\n\n\nregisteredreports\n\n\n\n\npreprints\n\n\n\n\npreregistration\n\n\n\n\nliterateprogramming\n\n\n\n\nopen data"
  },
  {
    "objectID": "posts/literate-programming/index.html",
    "href": "posts/literate-programming/index.html",
    "title": "Literate programming",
    "section": "",
    "text": "Literate programming refers to the integration of code and prose in a reproducible document. This practice is not yet mainstream in linguistics, although it holds several advantages as opposed to traditional reporting methods. Traditionally, statistical analysis, plots, tables, citations and captions would be created and manually and inserted into a manuscript. One potential issue with this approach is the increased probability of reported errors. For example, a recent study found that…(Roettger analysis of Labphon). A literate programming approach to manuscript creation would plausibly reduce the quantity of these errors, and it would make the correct information traceable more often. Additionally, updates to the data would be (almost) automatically integrated into a given manuscript if the necssary scripts are run again.\nThe present tutorial will provide an example of literate programming specifically for linguists by using an open dataset in linguistics and reported a mock analysis While the emphasis of this tutorial will be on creating a simple working example in Rmarkdown, it is important to note that literate programming can be applied within R to APA style manuscripts (see the Papaja package), in slideshows (see Xaringan) and in other programs entirely (qmd, python, jupitor notebooks)"
  },
  {
    "objectID": "posts/literate-programming/index.html#reporting-descriptive-statistics",
    "href": "posts/literate-programming/index.html#reporting-descriptive-statistics",
    "title": "Literate programming",
    "section": "Reporting descriptive statistics",
    "text": "Reporting descriptive statistics\nIn general all, inline reporting occurs in Rmardown between backticks, i.e., ` `. Specifically, you have to wrap the r code with `r ` to integrate it into your document. For instance, if we want to report the overall mean for the column DurationOfPrefix, we can simply put r code such as, mean(durationsGe$DurationOfPrefix) between to back ticks like this:\n\n\nThe mean duration is `r mean(durationsGe$DurationOfPrefix)`. \n\n\n\nWhich would be rendered as:\n\nThe mean duration is 0.1252515\n\nThere are several decimal points here, though! We probably don’t want that, so if we haven’t rounded the data previously, we can do so inline by using the round function:\n\n\nThe mean duration was `r round(mean(durationsGe$DurationOfPrefix), digits = 2)`. \n\n\n\nNow the code is rendered in prose as:\n\nThe mean duration was 0.13.\n\nAs you can see, this can get rather long in a hurry. Another option is to use an code chunk to calculate summary statistics and assign them to objects. Then you can simply use the objects with inline chunks. For instance, we likely also want to report how many participants are in our dataset. Let’s do this and report it in prose.\n\nCodemean_duration  <- round(mean(durationsGe$DurationOfPrefix), digits = 2)\nn_participants <- length(unique(durationsGe$Speaker))\n\n\n\n\nThere were `r n_participants` participants. \nThe mean duration was `r mean_duration`. \n\n\n\n\nThere were 132 participants. The mean duration was 0.13."
  },
  {
    "objectID": "posts/literate-programming/index.html#reporting-results-of-statistical-models",
    "href": "posts/literate-programming/index.html#reporting-results-of-statistical-models",
    "title": "Literate programming",
    "section": "Reporting results of statistical models",
    "text": "Reporting results of statistical models\nWe can also report the output statistical models and tests. Typically, the results of these tests can be stored in an object in R and extracted. I will provide an example with a t-test in R. First, we will run a t-test to see whether duration varies as a function of speaker sex:\n\nCodet_test_object <- t.test(DurationOfPrefix ~ Sex, data = durationsGe)\nt_test_object\n\n\n    Welch Two Sample t-test\n\ndata:  DurationOfPrefix by Sex\nt = -0.1949, df = 413.26, p-value = 0.8456\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -0.009955279  0.008159221\nsample estimates:\nmean in group female   mean in group male \n           0.1249141            0.1258121 \n\n\nFor a t-test, in APA guidelines we report degrees of freedom, the t-value, and the p-value. All of these are actually stored in the object we just created, and we can automate the reporting process.\nNote: The degree of freedom in this dataset are exaggerated due to the nested structure of the data and this t-test serves as an example only\nDegrees of Freedom\n\nr round(t_test_object$parameter, digits = 2)\n\n\n413.26\n\nThe t-value\n\nr round(t_test_object$statistic, digits = 2)\n\n\n-0.19\n\nThe p-value\n\nr round(t_test_object$p.value, digits = 2)\n\n\n0.85\n\nAll together\n\nt(r round(t_test_object\\(parameter, digits = 2)) = r round(t_test_object\\)statistic, digits = 2), p = r round(t_test_object$p.value, digits = 2)\n\n\nt(413.26) = -0.19, p = 0.85"
  },
  {
    "objectID": "posts/open-data/index.html",
    "href": "posts/open-data/index.html",
    "title": "Open data",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/positionality-statements/index.html",
    "href": "posts/positionality-statements/index.html",
    "title": "Positionality statements",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/preprints/index.html",
    "href": "posts/preprints/index.html",
    "title": "Preprints",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/preregistration/index.html",
    "href": "posts/preregistration/index.html",
    "title": "Preregistration",
    "section": "",
    "text": "A preregistration is a timestamped document that includes details about a study, such as research questions, hypotheses, methods, and analytic strategies. Preregistration differs from other open science practices, such as registered reports and preprints, in that it is written prior to data collection and is not peer reviewed. The amount of detail included in a preregistration can vary. In the simplest case, a preregistration can comprise merely a hypothesis or perhaps a brief description of the methods. On the other extreme, a detailed preregistration can include code, power analyses, participant exclusion criteria, etc., in addition to the information described in the simple case. In the following sections, we will provide more information about the different components that can be included in a preregistration with a specific focus on how preregistration can benefit linguistic research. More concretely, we will cover the who, why, what, and how for preregistering your study in linguistics."
  },
  {
    "objectID": "posts/preregistration/index.html#who-can-benefit-from-preregistration",
    "href": "posts/preregistration/index.html#who-can-benefit-from-preregistration",
    "title": "Preregistration",
    "section": "Who can benefit from preregistration?",
    "text": "Who can benefit from preregistration?\nEverybody! Preregistration is an important practice for conducting open science and anyone interested in reducing the likelihood of committing questionable research practices (QRPs) and making their research more transparent should consider using them. This tutorial focuses specifically on preregistration for researchers in any area of linguistics."
  },
  {
    "objectID": "posts/preregistration/index.html#why-preregister-your-study",
    "href": "posts/preregistration/index.html#why-preregister-your-study",
    "title": "Preregistration",
    "section": "Why preregister your study?",
    "text": "Why preregister your study?\nResearchers have to make critical choices throughout the process of designing and conducting research. To give a concrete example, consider a phonotician interested in investigating lexical stress. In this case, the researcher would likely focus on some acoustic correlates associated with stress, such as pitch, duration, and/or intensity. Aside from choosing which acoustic correlate(s) to measure, she would also need to specify the domain in which these measurements are taken. Is it the nucleus of the stressed/unstressed syllables? Or perhaps the entire syllable? Where exactly is the measurement taken? The mid-point, perhaps? Or maybe an average over the entire syllable? All of these choices can have crucial consequences on downstream analyses. This type of inherent flexibility is referred to as researcher degrees of freedom. The purpose of preregisteration is to document all of these critical aspects of the study. Furthermore, preregistration can deter individuals from QRPs, such as HARKing or p-hacking, by requiring them to explicitly state critical decisions in the research pipeline prior to ever collecting data.\n\nFor more information about QRPs and how they relate to the replicability crisis see What is open science?.\nThere are many additional benefits to preregistering studies. Preregistration can serve as proof one is engaging in confirmatory data analysis (as opposed to exploratory data analysis), as it establishes a timeline of decisions made before and after data collection. Moreover, by including a greater level of detail in the preregistration, the researcher is forced to think about aspects of their study that might typically be left for a later stage, e.g., statistical analyses. This necessarily requires the researcher to invest more time upfront, but often has the benefit of increasing the likelihood of discovering critical errors in the study design."
  },
  {
    "objectID": "posts/preregistration/index.html#what-should-you-pregister",
    "href": "posts/preregistration/index.html#what-should-you-pregister",
    "title": "Preregistration",
    "section": "What should you pregister?",
    "text": "What should you pregister?\nIn short, you can preregister anything that you think warrants being timestamped prior to conducting your study. What exactly this entails will vary widely depending on your area of linguistics and the type of study you are conducting. To illustrate, we’ll consider a concrete example.\nLet’s imagine you are a psycholinguist preparing an experiment using self-paced reading. You might want to focus on the research questions, hypotheses, and critical details related to the methodology, such as who the participants are, how you plan to recruit them, how many you plan to recruit, etc. You also might consider explaining what the critical variables are that you will manipulate with your design, what transformations you plan to perform on the data, and what modeling strategies you will use for statistical inferences. All of these decisions, while important, might not be applicaple in every situation. To summarize, the type of information included in a preregistration will likely be related to one of the following:\n\nRQ/Hypotheses\nMethod\nAnalysis\n\nImportantly, it may be overwhelming to incorporate all of them in your preregistration if you are just getting started in Open Science. That’s fine. Feel free to pick what you think might be most relevant to your study to begin, and, with time and practice, you will get better at deciding what is relevant for your research.\nLevel of details\nA lot of concerns of putting Open Science into practice or doing preregistration are about the possible overload of “extra work”. On the contrary, preregistration should be helping us work in a more efficient manner both in the long run and in short terms. Besides, you have complete control of how much detail you want to include. The more detailed the preregistration is, the more effort you need to put into, and as a result the less work down the road. Here we only propose some of the levels of details that may help you determine how much details you can incorporate in your preregistration (Figure 2). The darker the shade, the more detailed it is (thus more work). Again, you can always incorporate different levels of details in different parts.\n\n\n\n\nFigure 1: Levels of detail"
  },
  {
    "objectID": "posts/preregistration/index.html#how-to-preregister-your-study",
    "href": "posts/preregistration/index.html#how-to-preregister-your-study",
    "title": "Preregistration",
    "section": "How to preregister your study",
    "text": "How to preregister your study\nThere are websites dedicated to Open Science practices. OSF is one and it provide platform and/or template we can use.\n\n\nOSF\nGithub\nAspredicted.org\nBy hand\n\n\n\n\n\nOSF\n\nStart from scratch\nStart from an existing OSF project or component\n\n\n\n\n\nPre registration involves making a plan for your research project before collecting and analyzing data. This plan can be documented and shared on Github, which is a popular web-based hosting service for version control and collaborative software development.\nHere are the steps to set up a pre registration for your research on Github:\n\nCreate a Github account: If you do not already have a Github account, create one by visiting the Github homepage and following the instructions.\nCreate a new repository: Once you are logged in to Github, you can create a new repository to store your pre registration documents. Click the “New” button in the top left corner of the screen and follow the prompts to create a new repository.\nChoose a template: Github provides several templates for different types of repositories. You can choose a template that is specifically designed for pre registration documents, such as the Open Science Framework (OSF) Preregistration template.\nAdd your pre registration documents: Once you have chosen a template, you can add your pre registration documents to the repository. These documents should include a detailed description of your research question, hypotheses, methods, and analysis plan. You can use Markdown, a lightweight markup language, to format your documents on Github.\nShare your repository: Once your pre registration documents are complete, you can share your repository with other researchers or members of the public. You can do this by sharing the link to your repository or by inviting collaborators to contribute to the project.\nUpdate your repository: As you collect and analyze data, you may need to update your pre registration documents. You can do this by making changes to your documents on Github and committing the changes to the repository.\n\nBy setting up a preregistration on Github, you can make your research more transparent and reproducible. Other researchers can review your plan and provide feedback, and you can use the repository to document any changes you make to your research plan over time.\n\n\n\nOne author creates the pre-registration.\nParticipating authors are emailed, requesting approval.\nIf all approve, it is saved but remains private until an author makes it public; or remains private forever.(Why?)\nAuthors may share an anonymous version of the pre-registration with reviewers.\nIf made public, the final .pdf (sample) is automatically stored in the web-archive.\n\n\n\nWrite, timestamp + freeze, and then check yourself\nTo set up a pre registration for your research from scratch on paper, you can follow these steps:\n\nDefine your research question and hypotheses: Start by identifying the research question you are trying to answer and any hypotheses you have about the expected results.\nSelect your variables and measures: Identify the independent and dependent variables in your study and describe the measures you will use to operationalize these variables.\nDetermine your sample size and recruitment strategy: Specify the number of participants you plan to recruit and describe how you will recruit them.\nOutline your research design: Describe the research design you will use to address your research question, such as a between-subjects or within-subjects design.\nSpecify your data analysis plan: Describe the statistical analyses you plan to use to test your hypotheses, including any planned exploratory analyses and methods to handle missing data.\nPlan for ethical considerations: Address any ethical considerations in your study, such as obtaining informed consent from participants, ensuring confidentiality and privacy, and handling any potential risks or harms.\nConsider any potential limitations: Anticipate any potential limitations of your study, such as sampling bias or measurement error.\nWrite up your pre registration plan: Once you have completed these steps, write up your pre registration plan in a clear and concise manner on paper. Be sure to include all relevant information, such as your research question, hypotheses, variables and measures, sample size and recruitment strategy, research design, data analysis plan, ethical considerations, and potential limitations.\n\n\n\n\nTo read more about preregistration in linguisticis: https://www.degruyter.com/document/doi/10.1515/ling-2019-0048/html?lang=en\nReference Kathawalla, U. K., Silverstein, P., & Syed, M. (2021). Easing into open science: A guide for graduate students and their advisors. Collabra: Psychology, 7(1)"
  },
  {
    "objectID": "posts/registered-reports/index.html",
    "href": "posts/registered-reports/index.html",
    "title": "Registered reports",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/reproducible-code-projects/index.html",
    "href": "posts/reproducible-code-projects/index.html",
    "title": "Reproducible code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/what-is-open-science/index.html",
    "href": "posts/what-is-open-science/index.html",
    "title": "What is open science?",
    "section": "",
    "text": "What is open science? Parsons et al. (2022) provide the following definition:\n\nAn umbrella term reflecting the idea that scientific knowledge of all kinds, where appropriate, should be openly accessible, transparent, rigorous, reproducible, replicable, accumulative, and inclusive, all which are considered fundamental features of the scientific endeavour. Open science consists of principles and behaviors that promote transparent, credible, reproducible, and accessible science. Open science has six major aspects: open data, open methodology, open source, open access, open peer review, and open educational resources.\n\nThat sounds wonderful, right? But you might be asking yourself why the push for Open Science? It may come as a surprise to some, but the open, transparent research practices described by Parsons et al. (2022) have not been the norm in scholarly research.\nTo properly contextualize the need for Open Science, we have to go back to the early 2010’s. Around this time, several fields of research embarked on large-scale replication projects to scrutinize some of their major findings. One example of these projects took place in psychology. This particular project tested whether they could replicate 100 influential findings (Open Science Collaboration 2015). They found the approximately 53% of the findings did not replicate. This project inspired similar large-scale replication projects in other fields, yielding similar results in economics (Camerer et al. 2016), social sciences (Camerer et al. 2018), and cancer research (Errington et al. 2021). These alarming findings are now referred to as the replication (or reproducibility) crisis. Researchers have pointed to questionable research practices (QRPs), p-hacking, HARKing, small sample sizes, poor theory, lack of transparency, etc. as factors that ultimately led to the replication crisis, though it is likely that other factors are at play.\n\nTake a second to consider your field of study. How many important findings do you think would replicate? If you were to replicate 100 of the most influential findings, how many would need to replicate for you to have confidence in your field?\n\nIn the aftermath of the replication crisis we have seen a push for increased transparency and reproducible methodology to help mitigate the effects of questionable research practices. The resulting methodological framework and associated techniques have reshaped research methods in psychology and have slowly but surely made their way into adjacent fields. This website is dedicated to making open science practices understandable and accessible to researchers in the speech sciences from all backgrounds and at every stage, from students/early career researchers to senior researchers.\nTo this end, we have highlighted 7 areas in which speech researchers can engage in Open Science:\n\nLiterate programming\nOpen data\nPositionality statements\nPreprints\nPreregistration\nRegistered reports\nReproducible code/projects\n\nThroughout this website you will find tutorials designed to get you up and running in each of these areas so that you can engage in Open Science practices.\nSee Figure 1\n\n\n\n\n\nFigure 1: This is a caption\n\n\n\n\n\n\n\n\nReferences\n\nCamerer, Colin F, Anna Dreber, Eskil Forsell, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2016. “Evaluating Replicability of Laboratory Experiments in Economics.” Science 351 (6280): 1433–36. https://doi.org/10.1126/science.aaf091.\n\n\nCamerer, Colin F, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2018. “Evaluating the Replicability of Social Science Experiments in Nature and Science Between 2010 and 2015.” Nature Human Behaviour 2 (9): 637–44. https://doi.org/10.1038/s41562-018-0399-z.\n\n\nErrington, Timothy M, Maya Mathur, Courtney K Soderberg, Alexandria Denis, Nicole Perfito, Elizabeth Iorns, and Brian A Nosek. 2021. “Investigating the Replicability of Preclinical Cancer Biology.” Elife 10: e71601. https://doi.org/10.7554/eLife.71601.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. https://doi.org/10.1126/science.aac4716.\n\n\nParsons, Sam, Flávio Azevedo, Mahmoud M Elsherif, Samuel Guay, Owen N Shahim, Gisela H Govaart, Emma Norris, et al. 2022. “A Community-Sourced Glossary of Open Scholarship Terms.” Nature Human Behaviour 6 (3): 312–18. https://doi.org/10.1038/s41562-021-01269-4.\n\nCitationBibTeX citation:@online{v.casillas2023,\n  author = {Joseph V. Casillas},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJoseph V. Casillas. 2023. “What Is Open Science?” February\n21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nPreregistration\n\n\n\n\n\n\n\nopen science\n\n\nreregistration\n\n\n\n\nAll about preregistration\n\n\n\n\n\n\nNov 21, 2023\n\n\nJiawei Shao, Adrija Gadamsetty, Katherine Taveras\n\n\n\n\n\n\n  \n\n\n\n\nWhat is open science?\n\n\n\n\n\n\n\ninfo\n\n\n\n\nA quick primer on Open Science and reproducible research.\n\n\n\n\n\n\nFeb 21, 2023\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\nLiterate programming\n\n\n\n\n\n\n\ninfo\n\n\ncoding\n\n\nliterate programming\n\n\n\n\nIntroduction to literate programming.\n\n\n\n\n\n\nFeb 20, 2023\n\n\nKyle Parish, Isabelle Chang\n\n\n\n\n\n\n  \n\n\n\n\nOpen data\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\n  \n\n\n\n\nPositionality statements\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nPreprints\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\n  \n\n\n\n\nRegistered reports\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\n  \n\n\n\n\nReproducible code/projects\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nTBD\n\n\n\n\n\n\nNo matching items"
  }
]